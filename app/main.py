import uuid
import json
import logging
from fastapi import FastAPI, HTTPException, Depends, status, Path as FastAPIPath
from typing import List

from app.models import PointUpsertRequest, Event, SchedulePoint, SchedulePointResponse
from app.db import (
    get_clickhouse_client,
    store_event_in_db,
    get_current_point_version_and_command,
    check_command_id_globally_processed,
    get_active_points_for_route
)
from app.config import settings
import clickhouse_connect

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

app = FastAPI(title="SchedulePoint Service with Event Sourcing")

# Dependency for ClickHouse client
def get_db():
    client = None
    try:
        client = get_clickhouse_client()
        yield client
    except Exception as e:
        logger.error(f"Database connection failed: {e}")
        raise HTTPException(status_code=503, detail="Service unavailable (DB connection error)")
    finally:
        if client:
            client.close()

@app.on_event("startup")
async def startup_event():
    logger.info("Application startup...")
    # Attempt to connect to ClickHouse to ensure it's available and tables exist
    # This is a good place to run migrations or checks in a real app
    try:
        client = get_clickhouse_client()
        # Basic check if tables exist (optional, init script should handle creation)
        client.command(f"SELECT 1 FROM {settings.CLICKHOUSE_DATABASE}.schedule_events LIMIT 1")
        client.command(f"SELECT 1 FROM {settings.CLICKHOUSE_DATABASE}.schedule_points LIMIT 1")
        logger.info("Successfully connected to ClickHouse on startup and tables seem to exist.")
        client.close()
    except Exception as e:
        logger.error(f"Failed to verify ClickHouse setup on startup: {e}. "
                     "Ensure ClickHouse is running and init.sql has been executed.")
        # Depending on severity, you might want to prevent startup
        # raise RuntimeError("Could not verify ClickHouse setup on startup")


@app.post("/points", status_code=status.HTTP_202_ACCEPTED, response_model=Event)
async def upsert_point(
    request_data: PointUpsertRequest,
    client: clickhouse_connect.driver.client.Client = Depends(get_db)
):
    """
    Creates or updates a SchedulePoint by persisting an event.
    The `command_id` is used for idempotency.
    Optimistic locking is based on `version` for the specific point (`route_id`, `point.id`).
    """
    point_data = request_data.point
    command_id = request_data.command_id
    point_id = point_data.id
    route_id = point_data.route_id

    logger.info(f"Received upsert command {command_id} for point {point_id} on route {route_id}")

    # Idempotency Check (Global Command ID)
    # If a command_id has been processed anywhere, we might reject or log.
    # For CRU, if the same command tries to update different entities, it's problematic.
    # If it's a retry of the same logical operation, versioning should handle it.
    if check_command_id_globally_processed(client, command_id):
        # This is a simple check. A more robust system might return the original event or a 409.
        # For this prototype, we'll allow reprocessing, relying on versioning.
        logger.warning(f"Command ID {command_id} has been processed before. Proceeding with upsert logic.")
        # If you wanted to be strict:
        # raise HTTPException(status_code=status.HTTP_409_CONFLICT,
        # detail=f"Command ID {command_id} has already been processed.")

    try:
        # Optimistic Locking: Get current version for the specific point
        current_version, _ = get_current_point_version_and_command(client, route_id, point_id)
        next_version = current_version + 1

        logger.info(f"Point {point_id} on route {route_id}: current_version={current_version}, next_version={next_version}")

        # Create the event
        # The payload IS the full SchedulePoint object as a JSON string
        event = Event(
            route_id=route_id,
            version=next_version,
            command_id=command_id,
            event_type="SchedulePointUpserted", # Single event type for create/update
            payload=point_data.model_dump_json(), # Serialize the Pydantic model to JSON string
            # event_id and created_at are auto-generated by Pydantic model
        )

        store_event_in_db(client, event)
        logger.info(f"Event {event.event_id} for command {command_id} (point {point_id} v{next_version}) stored.")

        # HTTP 202 Accepted: The request is accepted for processing,
        # but the processing isn't necessarily complete (MV update is async).
        return event

    except Exception as e:
        logger.error(f"Error processing command {command_id} for point {point_id}: {e}", exc_info=True)
        # More specific error handling could be added here
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Internal server error: {str(e)}")


@app.get("/routes/{route_id}/points", response_model=List[SchedulePointResponse])
async def get_route_points(
    route_id: uuid.UUID = FastAPIPath(..., description="The ID of the route to retrieve points for"),
    client: clickhouse_connect.driver.client.Client = Depends(get_db)
):
    """
    Retrieves all actual (non-deleted) schedule points for a given route_id
    from the materialized read model.
    """
    logger.info(f"Request to get active points for route_id: {route_id}")
    try:
        points = get_active_points_for_route(client, route_id)
        # No special handling for "not found" needed if an empty list is acceptable.
        # If route_id itself must exist, additional checks might be needed.
        return points
    except Exception as e:
        logger.error(f"Error retrieving points for route_id {route_id}: {e}", exc_info=True)
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))

# For local development without Docker, if needed:
# if __name__ == "__main__":
#     import uvicorn
#     uvicorn.run(app, host=settings.APP_HOST, port=settings.APP_PORT)